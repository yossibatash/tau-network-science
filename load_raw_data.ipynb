{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from datetime import datetime, timedelta\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spark = SparkSession.builder.appName('loadRawData').getOrCreate()\n",
    "file = '/Users/ybatash/PycharmProjects/jupyter/tau-network-science/data/raw_data/flightlist_*.csv.gz'\n",
    "df = spark.read.csv(path=file, header=True)\n",
    "df = df.withColumn(\"filename\", input_file_name())\n",
    "df.createOrReplaceTempView('T')\n",
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------------+------------------+----------------+---------------------+-----------------+---------------+--------------------+---------------------------+------------------+-----------------+------------+-------------------+--------------------+-------------------+-------------------+--------------------+-------------------+\n",
      "|row_count|nn_count_callsign|nn_count_number   |nn_count_icao24 |nn_count_registration|nn_count_typecode|nn_count_origin|nn_count_destination|nn_count_origin_destination|nn_count_firstseen|nn_count_lastseen|nn_count_day|nn_count_latitude_1|nn_count_longitude_1|nn_count_altitude_1|nn_count_latitude_2|nn_count_longitude_2|nn_count_altitude_2|\n",
      "+---------+-----------------+------------------+----------------+---------------------+-----------------+---------------+--------------------+---------------------------+------------------+-----------------+------------+-------------------+--------------------+-------------------+-------------------+--------------------+-------------------+\n",
      "|32840850 |100.0            |20.624621469907144|99.9997807608512|89.5452279706524     |65.83634711038235|100.0          |100.0               |100.0                      |100.0             |100.0            |100.0       |100.0              |100.0               |100.0              |99.99718034094732  |99.99718034094732   |97.27336229117091  |\n",
      "+---------+-----------------+------------------+----------------+---------------------+-----------------+---------------+--------------------+---------------------------+------------------+-----------------+------------+-------------------+--------------------+-------------------+-------------------+--------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select \n",
    "        count(*) as row_count,\n",
    "        sum( case when callsign     is not null then 1 else 0 end)/count(*) * 100 as nn_count_callsign     ,\n",
    "        sum( case when number       is not null then 1 else 0 end)/count(*) * 100 as nn_count_number       ,\n",
    "        sum( case when icao24       is not null then 1 else 0 end)/count(*) * 100 as nn_count_icao24       ,\n",
    "        sum( case when registration is not null then 1 else 0 end)/count(*) * 100 as nn_count_registration ,\n",
    "        sum( case when typecode     is not null then 1 else 0 end)/count(*) * 100 as nn_count_typecode     ,\n",
    "        sum( case when origin       is not null then 1 else 0 end)/count(*) * 100 as nn_count_origin       ,\n",
    "        sum( case when destination  is not null then 1 else 0 end)/count(*) * 100 as nn_count_destination  ,\n",
    "\n",
    "       sum( case\n",
    "                  when origin       is not null and\n",
    "                       destination  is not null\n",
    "                    then 1 else 0 end)/count(*) * 100 as nn_count_origin_destination       ,\n",
    "\n",
    "\n",
    "        sum( case when firstseen    is not null then 1 else 0 end)/count(*) * 100 as nn_count_firstseen    ,\n",
    "        sum( case when lastseen     is not null then 1 else 0 end)/count(*) * 100 as nn_count_lastseen     ,\n",
    "        sum( case when day          is not null then 1 else 0 end)/count(*) * 100 as nn_count_day          ,\n",
    "        sum( case when latitude_1   is not null then 1 else 0 end)/count(*) * 100 as nn_count_latitude_1   ,\n",
    "        sum( case when longitude_1  is not null then 1 else 0 end)/count(*) * 100 as nn_count_longitude_1  ,\n",
    "        sum( case when altitude_1   is not null then 1 else 0 end)/count(*) * 100 as nn_count_altitude_1   ,\n",
    "        sum( case when latitude_2   is not null then 1 else 0 end)/count(*) * 100 as nn_count_latitude_2   ,\n",
    "        sum( case when longitude_2  is not null then 1 else 0 end)/count(*) * 100 as nn_count_longitude_2  ,\n",
    "        sum( case when altitude_2   is not null then 1 else 0 end)/count(*) * 100 as nn_count_altitude_2\n",
    "from T\n",
    "where origin is not null and destination  is not null\n",
    "\"\"\").show(10, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------------------+---------+-----------------+------------------+-----------------+---------------------+------------------+---------------+--------------------+---------------------------+------------------+-----------------+------------+-------------------+--------------------+-------------------+-------------------+--------------------+-------------------+\n",
      "|filename                                                                                                 |row_count|nn_count_callsign|nn_count_number   |nn_count_icao24  |nn_count_registration|nn_count_typecode |nn_count_origin|nn_count_destination|nn_count_origin_destination|nn_count_firstseen|nn_count_lastseen|nn_count_day|nn_count_latitude_1|nn_count_longitude_1|nn_count_altitude_1|nn_count_latitude_2|nn_count_longitude_2|nn_count_altitude_2|\n",
      "+---------------------------------------------------------------------------------------------------------+---------+-----------------+------------------+-----------------+---------------------+------------------+---------------+--------------------+---------------------------+------------------+-----------------+------------+-------------------+--------------------+-------------------+-------------------+--------------------+-------------------+\n",
      "|file:///Users/ybatash/PycharmProjects/jupyter/tau-network-science/data/raw_data/flightlist_2019_07.csv.gz|1497770  |100.0            |16.91721692916803 |100.0            |88.6926564158716     |69.73166774604913 |100.0          |100.0               |100.0                      |100.0             |100.0            |100.0       |100.0              |100.0               |100.0              |99.99759642668768  |99.99759642668768   |96.8616676792832   |\n",
      "|file:///Users/ybatash/PycharmProjects/jupyter/tau-network-science/data/raw_data/flightlist_2019_05.csv.gz|1337337  |100.0            |10.268242036225724|100.0            |89.22754698329591    |72.67210882522505 |100.0          |100.0               |100.0                      |100.0             |100.0            |100.0       |100.0              |100.0               |100.0              |99.99648555300571  |99.99648555300571   |96.84813924986746  |\n",
      "|file:///Users/ybatash/PycharmProjects/jupyter/tau-network-science/data/raw_data/flightlist_2020_10.csv.gz|1263798  |100.0            |27.93460663808615 |99.99889222803012|84.41008768806407    |52.71578211074871 |100.0          |100.0               |100.0                      |100.0             |100.0            |100.0       |100.0              |100.0               |100.0              |99.99723057007527  |99.99723057007527   |99.6191638220665   |\n",
      "|file:///Users/ybatash/PycharmProjects/jupyter/tau-network-science/data/raw_data/flightlist_2021_02.csv.gz|1005321  |100.0            |35.439128397795336|99.99880635140418|83.00910853349328    |53.449495235850044|100.0          |100.0               |100.0                      |100.0             |100.0            |100.0       |100.0              |100.0               |100.0              |99.99721481994308  |99.99721481994308   |99.41720107309008  |\n",
      "|file:///Users/ybatash/PycharmProjects/jupyter/tau-network-science/data/raw_data/flightlist_2020_11.csv.gz|1132369  |100.0            |24.027415091723633|99.99867534346136|84.54373088631003    |52.5736751889181  |100.0          |100.0               |100.0                      |100.0             |100.0            |100.0       |100.0              |100.0               |100.0              |99.99699744517909  |99.99699744517909   |99.45274022867105  |\n",
      "|file:///Users/ybatash/PycharmProjects/jupyter/tau-network-science/data/raw_data/flightlist_2019_10.csv.gz|1687765  |100.0            |19.86562110246391 |100.0            |88.35993162555214    |69.66005338420929 |100.0          |100.0               |100.0                      |100.0             |100.0            |100.0       |100.0              |100.0               |100.0              |99.99733375203301  |99.99733375203301   |96.88688887374724  |\n",
      "|file:///Users/ybatash/PycharmProjects/jupyter/tau-network-science/data/raw_data/flightlist_2019_03.csv.gz|1158298  |100.0            |6.123726364027219 |100.0            |89.31932887737007    |72.78023444743926 |100.0          |100.0               |100.0                      |100.0             |100.0            |100.0       |100.0              |100.0               |100.0              |99.99732365936917  |99.99732365936917   |96.04385054623249  |\n",
      "|file:///Users/ybatash/PycharmProjects/jupyter/tau-network-science/data/raw_data/flightlist_2020_07.csv.gz|1221873  |100.0            |22.9148201163296  |100.0            |99.2379731772451     |64.31273954003403 |100.0          |100.0               |100.0                      |100.0             |100.0            |100.0       |100.0              |100.0               |100.0              |99.99648081265403  |99.99648081265403   |96.84566235607137  |\n",
      "|file:///Users/ybatash/PycharmProjects/jupyter/tau-network-science/data/raw_data/flightlist_2019_06.csv.gz|1383779  |100.0            |12.074110099950932|100.0            |88.52439587535292    |70.81463152714414 |100.0          |100.0               |100.0                      |100.0             |100.0            |100.0       |100.0              |100.0               |100.0              |99.99689256738252  |99.99689256738252   |96.44921624045459  |\n",
      "|file:///Users/ybatash/PycharmProjects/jupyter/tau-network-science/data/raw_data/flightlist_2020_03.csv.gz|1320340  |100.0            |32.63962312737628 |100.0            |87.92856385476469    |65.1436751139858  |100.0          |100.0               |100.0                      |100.0             |100.0            |100.0       |100.0              |100.0               |100.0              |99.99803081024584  |99.99803081024584   |96.86830664828756  |\n",
      "+---------------------------------------------------------------------------------------------------------+---------+-----------------+------------------+-----------------+---------------------+------------------+---------------+--------------------+---------------------------+------------------+-----------------+------------+-------------------+--------------------+-------------------+-------------------+--------------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select \n",
    "        filename,\n",
    "        count(*) as row_count,\n",
    "        sum( case when callsign     is not null then 1 else 0 end)/count(*) * 100 as nn_count_callsign     ,\n",
    "        sum( case when number       is not null then 1 else 0 end)/count(*) * 100 as nn_count_number       ,\n",
    "        sum( case when icao24       is not null then 1 else 0 end)/count(*) * 100 as nn_count_icao24       ,\n",
    "        sum( case when registration is not null then 1 else 0 end)/count(*) * 100 as nn_count_registration ,\n",
    "        sum( case when typecode     is not null then 1 else 0 end)/count(*) * 100 as nn_count_typecode     ,\n",
    "        sum( case when origin       is not null then 1 else 0 end)/count(*) * 100 as nn_count_origin       ,\n",
    "        sum( case when destination  is not null then 1 else 0 end)/count(*) * 100 as nn_count_destination  ,\n",
    "\n",
    "       sum( case\n",
    "                  when origin       is not null and\n",
    "                       destination  is not null\n",
    "                    then 1 else 0 end)/count(*) * 100 as nn_count_origin_destination       ,\n",
    "\n",
    "\n",
    "        sum( case when firstseen    is not null then 1 else 0 end)/count(*) * 100 as nn_count_firstseen    ,\n",
    "        sum( case when lastseen     is not null then 1 else 0 end)/count(*) * 100 as nn_count_lastseen     ,\n",
    "        sum( case when day          is not null then 1 else 0 end)/count(*) * 100 as nn_count_day          ,\n",
    "        sum( case when latitude_1   is not null then 1 else 0 end)/count(*) * 100 as nn_count_latitude_1   ,\n",
    "        sum( case when longitude_1  is not null then 1 else 0 end)/count(*) * 100 as nn_count_longitude_1  ,\n",
    "        sum( case when altitude_1   is not null then 1 else 0 end)/count(*) * 100 as nn_count_altitude_1   ,\n",
    "        sum( case when latitude_2   is not null then 1 else 0 end)/count(*) * 100 as nn_count_latitude_2   ,\n",
    "        sum( case when longitude_2  is not null then 1 else 0 end)/count(*) * 100 as nn_count_longitude_2  ,\n",
    "        sum( case when altitude_2   is not null then 1 else 0 end)/count(*) * 100 as nn_count_altitude_2\n",
    "from T\n",
    "where origin is not null and destination  is not null\n",
    "group by 1\n",
    "\"\"\").show(10, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = spark.sql(\"\"\"\n",
    "select origin                   as origin_airport,\n",
    "       destination              as destination_airport,\n",
    "       count(*)                 as flights_count \n",
    "from   T       \n",
    "where   1=1\n",
    "        and origin is not null and destination  is not null\n",
    "        and filename like 'file:///Users/ybatash/PycharmProjects/jupyter/tau-network-science/data/raw_data/flightlist_2019_%.csv.gz'\n",
    "group by 1,2        \n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.repartition(1).write.format(\"com.databricks.spark.csv\").option(\"header\", \"true\").save(\"mydata.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------------+-------------+-----------------------+---------------------+-------------------------+-------------------------+\n",
      "|origin_airport|destination_airport|flights_count|distinct_callsign_count|distinct_icao24_count|min_firstseen            |max_firstseen            |\n",
      "+--------------+-------------------+-------------+-----------------------+---------------------+-------------------------+-------------------------+\n",
      "|01FA          |KLKR               |2            |2                      |2                    |2019-01-06 22:34:07+00:00|2019-01-09 15:36:47+00:00|\n",
      "|05IN          |KORD               |1            |1                      |1                    |2019-01-31 22:13:31+00:00|2019-01-31 22:13:31+00:00|\n",
      "|05MD          |KGAI               |1            |1                      |1                    |2019-01-31 20:34:36+00:00|2019-01-31 20:34:36+00:00|\n",
      "|06NC          |94NC               |1            |1                      |1                    |2019-01-08 20:22:32+00:00|2019-01-08 20:22:32+00:00|\n",
      "|08TE          |9TX5               |1            |1                      |1                    |2019-01-23 23:42:47+00:00|2019-01-23 23:42:47+00:00|\n",
      "|0FL9          |KX58               |1            |1                      |1                    |2019-01-05 20:50:35+00:00|2019-01-05 20:50:35+00:00|\n",
      "|0OK5          |KPWA               |1            |1                      |1                    |2019-01-24 17:14:40+00:00|2019-01-24 17:14:40+00:00|\n",
      "|11TX          |9XS4               |1            |1                      |1                    |2019-01-07 22:47:58+00:00|2019-01-07 22:47:58+00:00|\n",
      "|13CL          |KSAC               |2            |2                      |2                    |2019-01-11 23:06:05+00:00|2019-01-19 22:46:02+00:00|\n",
      "|13CL          |KVCB               |2            |1                      |1                    |2019-01-10 20:09:54+00:00|2019-01-24 22:09:07+00:00|\n",
      "+--------------+-------------------+-------------+-----------------------+---------------------+-------------------------+-------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select origin                   as origin_airport,\n",
    "       destination              as destination_airport,\n",
    "       count(*)                 as flights_count,\n",
    "       count(distinct callsign) as distinct_callsign_count,\n",
    "       count(distinct icao24)   as distinct_icao24_count,\n",
    "       min(firstseen)           as min_firstseen,\n",
    "       max(firstseen)           as max_firstseen \n",
    "from   T       \n",
    "where   1=1\n",
    "        and origin is not null and destination  is not null\n",
    "        and filename = 'file:///Users/ybatash/PycharmProjects/jupyter/tau-network-science/data/raw_data/flightlist_2019_01.csv.gz'\n",
    "group by 1,2        \n",
    "\"\"\").show(10, False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (my_test_env)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
