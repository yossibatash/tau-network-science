{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this Spark ETL process we are creating dim Airplanes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from datetime import datetime, timedelta\n",
    "from pyspark.sql.functions import *\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "spark = SparkSession.builder.appName('FactFlights').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 - Load flights data (OpenSky data)\n",
    "\n",
    "file = f'{cwd}/data/raw_data/flights/flightlist_*.csv.gz'\n",
    "fdf = spark.read.csv(path=file, header=True)\n",
    "fdf = fdf.withColumn(\"filename\", input_file_name())\n",
    "fdf.createOrReplaceTempView('FDF')\n",
    "# fdf.printSchema()\n",
    "\n",
    "# flightlist_*.csv.gz (downloaded from - https://zenodo.org/record/4601479#.YLaEU5MzYUH).\n",
    "# Schema:\n",
    "# root\n",
    "#  |-- callsign: string (nullable = true)\n",
    "#  |-- number: string (nullable = true)\n",
    "#  |-- icao24: string (nullable = true)\n",
    "#  |-- registration: string (nullable = true)\n",
    "#  |-- typecode: string (nullable = true)\n",
    "#  |-- origin: string (nullable = true)\n",
    "#  |-- destination: string (nullable = true)\n",
    "#  |-- firstseen: string (nullable = true)\n",
    "#  |-- lastseen: string (nullable = true)\n",
    "#  |-- day: string (nullable = true)\n",
    "#  |-- latitude_1: string (nullable = true)\n",
    "#  |-- longitude_1: string (nullable = true)\n",
    "#  |-- altitude_1: string (nullable = true)\n",
    "#  |-- latitude_2: string (nullable = true)\n",
    "#  |-- longitude_2: string (nullable = true)\n",
    "#  |-- altitude_2: string (nullable = true)\n",
    "#  |-- filename: string (nullable = false)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 - Load dim airports\n",
    "\n",
    "# Covid19 \n",
    "file = f'{cwd}/data/dwh/dim_airports.csv'\n",
    "adf = spark.read.csv(path=file, header=True)\n",
    "adf.createOrReplaceTempView('ADF')\n",
    "# adf.printSchema()\n",
    "\n",
    "# owid-covid-data.csv (downloaded from - https://github.com/owid/covid-19-data/blob/master/public/data/README.md).\n",
    "# Schema:\n",
    "# root\n",
    "#  |-- airport_id: string (nullable = true)\n",
    "#  |-- airport_name: string (nullable = true)\n",
    "#  |-- airport_type: string (nullable = true)\n",
    "#  |-- airport_lat: string (nullable = true)\n",
    "#  |-- airport_lng: string (nullable = true)\n",
    "#  |-- country_id: string (nullable = true)\n",
    "#  |-- country_iso_3_code: string (nullable = true)\n",
    "#  |-- country_name: string (nullable = true)\n",
    "#  |-- country_lat: string (nullable = true)\n",
    "#  |-- country_lng: string (nullable = true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 - Load the Covid19 data set\n",
    "\n",
    "# Covid19 \n",
    "file = f'{cwd}/data/raw_data/covid19/owid-covid-data.csv'\n",
    "cdf = spark.read.csv(path=file, header=True)\n",
    "cdf.createOrReplaceTempView('CDF')\n",
    "# cdf.printSchema()\n",
    "\n",
    "# owid-covid-data.csv (downloaded from - https://github.com/owid/covid-19-data/blob/master/public/data/README.md).\n",
    "# Schema:\n",
    "# root\n",
    "#  |-- iso_code: string (nullable = true)\n",
    "#  |-- continent: string (nullable = true)\n",
    "#  |-- location: string (nullable = true)\n",
    "#  |-- date: string (nullable = true)\n",
    "#  |-- total_cases: string (nullable = true)\n",
    "#  |-- new_cases: string (nullable = true)\n",
    "#  |-- new_cases_smoothed: string (nullable = true)\n",
    "#  |-- total_deaths: string (nullable = true)\n",
    "#  |-- new_deaths: string (nullable = true)\n",
    "#  |-- new_deaths_smoothed: string (nullable = true)\n",
    "#  |-- total_cases_per_million: string (nullable = true)\n",
    "#  |-- new_cases_per_million: string (nullable = true)\n",
    "#  |-- new_cases_smoothed_per_million: string (nullable = true)\n",
    "#  |-- total_deaths_per_million: string (nullable = true)\n",
    "#  |-- new_deaths_per_million: string (nullable = true)\n",
    "#  |-- new_deaths_smoothed_per_million: string (nullable = true)\n",
    "#  |-- reproduction_rate: string (nullable = true)\n",
    "#  |-- icu_patients: string (nullable = true)\n",
    "#  |-- icu_patients_per_million: string (nullable = true)\n",
    "#  |-- hosp_patients: string (nullable = true)\n",
    "#  |-- hosp_patients_per_million: string (nullable = true)\n",
    "#  |-- weekly_icu_admissions: string (nullable = true)\n",
    "#  |-- weekly_icu_admissions_per_million: string (nullable = true)\n",
    "#  |-- weekly_hosp_admissions: string (nullable = true)\n",
    "#  |-- weekly_hosp_admissions_per_million: string (nullable = true)\n",
    "#  |-- new_tests: string (nullable = true)\n",
    "#  |-- total_tests: string (nullable = true)\n",
    "#  |-- total_tests_per_thousand: string (nullable = true)\n",
    "#  |-- new_tests_per_thousand: string (nullable = true)\n",
    "#  |-- new_tests_smoothed: string (nullable = true)\n",
    "#  |-- new_tests_smoothed_per_thousand: string (nullable = true)\n",
    "#  |-- positive_rate: string (nullable = true)\n",
    "#  |-- tests_per_case: string (nullable = true)\n",
    "#  |-- tests_units: string (nullable = true)\n",
    "#  |-- total_vaccinations: string (nullable = true)\n",
    "#  |-- people_vaccinated: string (nullable = true)\n",
    "#  |-- people_fully_vaccinated: string (nullable = true)\n",
    "#  |-- new_vaccinations: string (nullable = true)\n",
    "#  |-- new_vaccinations_smoothed: string (nullable = true)\n",
    "#  |-- total_vaccinations_per_hundred: string (nullable = true)\n",
    "#  |-- people_vaccinated_per_hundred: string (nullable = true)\n",
    "#  |-- people_fully_vaccinated_per_hundred: string (nullable = true)\n",
    "#  |-- new_vaccinations_smoothed_per_million: string (nullable = true)\n",
    "#  |-- stringency_index: string (nullable = true)\n",
    "#  |-- population: string (nullable = true)\n",
    "#  |-- population_density: string (nullable = true)\n",
    "#  |-- median_age: string (nullable = true)\n",
    "#  |-- aged_65_older: string (nullable = true)\n",
    "#  |-- aged_70_older: string (nullable = true)\n",
    "#  |-- gdp_per_capita: string (nullable = true)\n",
    "#  |-- extreme_poverty: string (nullable = true)\n",
    "#  |-- cardiovasc_death_rate: string (nullable = true)\n",
    "#  |-- diabetes_prevalence: string (nullable = true)\n",
    "#  |-- female_smokers: string (nullable = true)\n",
    "#  |-- male_smokers: string (nullable = true)\n",
    "#  |-- handwashing_facilities: string (nullable = true)\n",
    "#  |-- hospital_beds_per_thousand: string (nullable = true)\n",
    "#  |-- life_expectancy: string (nullable = true)\n",
    "#  |-- human_development_index: string (nullable = true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid19 = spark.sql(\"\"\"\n",
    "select  distinct\n",
    "        A.airport_id as airport_id,\n",
    "        A.country_id as country_id,\n",
    "--        L.iso_3_code as iso_3_code,\n",
    "        cast(C.date as date)       as report_date,\n",
    "        coalesce(C.total_cases, 0) as total_cases,\n",
    "        C.population               as population,\n",
    "        cast(C.total_cases as double)/cast(C.population as double) as color_weight\n",
    "from    ADF A left join CDF C\n",
    "        ON A.country_iso_3_code = C.iso_code\n",
    "where   1=1\n",
    "        and C.population is not null\n",
    "\"\"\")\n",
    "\n",
    "covid19.createOrReplaceTempView('covid19')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+----------+-------+\n",
      "|take_off_date|partition_key|partit_key|ddd    |\n",
      "+-------------+-------------+----------+-------+\n",
      "|2019-07-31   |2019         |7         |2019-07|\n",
      "|2019-07-31   |2019         |7         |2019-07|\n",
      "|2019-07-31   |2019         |7         |2019-07|\n",
      "|2019-07-31   |2019         |7         |2019-07|\n",
      "|2019-07-31   |2019         |7         |2019-07|\n",
      "|2019-07-31   |2019         |7         |2019-07|\n",
      "|2019-07-31   |2019         |7         |2019-07|\n",
      "|2019-07-31   |2019         |7         |2019-07|\n",
      "|2019-07-31   |2019         |7         |2019-07|\n",
      "|2019-07-31   |2019         |7         |2019-07|\n",
      "+-------------+-------------+----------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select  cast(firstseen as date) as take_off_date,\n",
    "        year(firstseen)   as partition_key,\n",
    "        month(firstseen)   as partit_key,\n",
    "        left(firstseen, 7) as partition_key\n",
    "        \n",
    "from    FDF\"\"\").show(10,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights = spark.sql(\"\"\"\n",
    "select  F.callsign      as callsign,\n",
    "        F.origin        as origin_airport_id,\n",
    "        CO.country_id   as origin_country_id,\n",
    "        CO.color_weight as origin_country_color_weight,\n",
    "        F.destination   as destination_airport_id,\n",
    "        CD.country_id   as destination_country_id,\n",
    "        CD.total_cases  as total_cases,\n",
    "        CD.population   as population,        \n",
    "        CD.color_weight as destination_country_color_weight,        \n",
    "        F.typecode      as aircraft_icao_code,\n",
    "        count(*)        as Weight,\n",
    "        cast(F.firstseen as date) as take_off_date,\n",
    "        left(F.firstseen, 7) as partition_key\n",
    "from    FDF F left join covid19 CO\n",
    "        ON  F.origin = CO.airport_id\n",
    "            and cast(F.firstseen as date) = CO.report_date\n",
    "        left join covid19 CD\n",
    "        ON  F.destination = CD.airport_id\n",
    "            and cast(F.firstseen as date) = CD.report_date\n",
    "where   1=1\n",
    "        and F.origin is not null and F.destination is not null\n",
    "        and F.origin<>F.destination\n",
    "group by 1,2,3,4,5,6,7,8,9,10,12,13   \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights.repartition(1).write \\\n",
    ".partitionBy('partition_key') \\\n",
    ".mode('overwrite') \\\n",
    ".format(\"com.databricks.spark.csv\") \\\n",
    ".option(\"header\", \"true\") \\\n",
    ".option(\"quoteAll\", \"true\") \\\n",
    ".save(\"flights\")\n",
    "\n",
    "# # Copy new file into proper data folder location\n",
    "# !cp ./flights/*.csv ./data/dwh/fact_flights.csv\n",
    "# # Delete Spark output folder\n",
    "# !rm -rf ./flights\n",
    "# # Check that the folder deleted\n",
    "# !ls ./flights/*.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights.createOrReplaceTempView('flights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_by_airports = spark.sql(\"\"\"\n",
    "select  origin_airport_id,\n",
    "        AVG(origin_country_color_weight) as origin_country_color_weight,\n",
    "        destination_airport_id,\n",
    "        AVG(destination_country_color_weight) as destination_country_color_weight,        \n",
    "        Sum(Weight) as Weight,\n",
    "        partition_key\n",
    "from    flights\n",
    "group by 1,3,6\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_by_airports.repartition(1).write \\\n",
    ".partitionBy('partition_key') \\\n",
    ".mode('overwrite') \\\n",
    ".format(\"com.databricks.spark.csv\") \\\n",
    ".option(\"header\", \"true\") \\\n",
    ".option(\"quoteAll\", \"true\") \\\n",
    ".save(\"flights_by_airports\")\n",
    "\n",
    "# # Copy new file into proper data folder location\n",
    "# !cp ./flights/*.csv ./data/dwh/fact_flights.csv\n",
    "# # Delete Spark output folder\n",
    "# !rm -rf ./flights\n",
    "# # Check that the folder deleted\n",
    "# !ls ./flights/*.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_by_country = spark.sql(\"\"\"\n",
    "select  origin_country_id,\n",
    "        AVG(origin_country_color_weight) as origin_country_color_weight,\n",
    "        destination_country_id,\n",
    "        AVG(destination_country_color_weight) as destination_country_color_weight,        \n",
    "        Sum(Weight) as Weight,\n",
    "        partition_key\n",
    "from    flights\n",
    "group by 1,3,4,6\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_by_country.repartition(1).write \\\n",
    ".partitionBy('partition_key') \\\n",
    ".mode('overwrite') \\\n",
    ".format(\"com.databricks.spark.csv\") \\\n",
    ".option(\"header\", \"true\") \\\n",
    ".option(\"quoteAll\", \"true\") \\\n",
    ".save(\"flights_by_country\")\n",
    "\n",
    "# # Copy new file into proper data folder location\n",
    "# !cp ./flights/*.csv ./data/dwh/fact_flights.csv\n",
    "# # Delete Spark output folder\n",
    "# !rm -rf ./flights\n",
    "# # Check that the folder deleted\n",
    "# !ls ./flights/*.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (my_test_env)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
